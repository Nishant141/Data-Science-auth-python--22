{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwynZ194bii5l5wGl8vkVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishant141/Data-Science-auth-python--22/blob/main/Copy_of_Data_Quality_Trial_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JA_q4L4iZ8p"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to scrape data from a website\n",
        "def scrape_data(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        entity_names = [element.text.strip() for element in soup.find_all(['a', 'span'])]\n",
        "\n",
        "        return entity_names\n",
        "    else:\n",
        "        print(f\"Failed to fetch data from {url}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "ogBjjCuB4QBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sam_url = ' https://sam.gov/data-services'\n",
        "eproc_url = 'https://eprocure.gov.in/eprocure/app'\n",
        "\n",
        "\n",
        "sam_data = scrape_data('https://sam.gov/data-services')\n",
        "eproc_data = scrape_data('https://eprocure.gov.in/eprocure/app')\n",
        "\n"
      ],
      "metadata": {
        "id": "1ESAHx8Fi0m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual Cleaning\n",
        "def manual_cleaning(entity_name):\n",
        "\n",
        "\n",
        "    cleaned_name = entity_name.strip().title()  # Example: Removing leading/trailing spaces and capitalizing.\n",
        "\n",
        "    return cleaned_name\n",
        "\n",
        "sam_data_cleaned = [manual_cleaning(name) for name in sam_data]\n",
        "eproc_data_cleaned = [manual_cleaning(name) for name in eproc_data]"
      ],
      "metadata": {
        "id": "vpdPZvtw4OAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "def standardize_name(entity_name):\n",
        "\n",
        "    standardized_name = entity_name.replace('Ltd.', '').replace('Inc.', '')  # Example: Removing suffixes.\n",
        "\n",
        "    return standardized_name\n",
        "\n",
        "global sam_data_cleaned\n",
        "sam_data_standardized = [standardize_name(name) for name in sam_data_cleaned]\n",
        "eproc_data_standardized = [standardize_name(name) for name in eproc_data_cleaned]"
      ],
      "metadata": {
        "id": "OEXIZXQEjzJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sam_subset = pd.DataFrame({'Original': sam_data, 'Cleaned': sam_data_standardized})\n",
        "eproc_subset = pd.DataFrame({'Original': eproc_data, 'Cleaned': eproc_data_standardized})\n",
        "\n",
        "\n",
        "sam_subset.to_csv('sam_cleaned_data.csv', index=False)\n",
        "eproc_subset.to_csv('eproc_cleaned_data.csv', index=False)"
      ],
      "metadata": {
        "id": "8slORNf0lngO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DumtqvRKkSWr",
        "outputId": "6fbc0036-e122-40ed-a7de-be8d3c85c461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.9-py3-none-any.whl (221 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/221.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im3CEHqVFXlh",
        "outputId": "013639f4-df6f-4f18-f3e8-36be8eee1e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.3.9\n",
            "    Uninstalling openai-1.3.9:\n",
            "      Successfully uninstalled openai-1.3.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "ncg73xUTED3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def automate_standardization(entity_names):\n",
        "    \"\"\"Standardizes the names of entities in the given list.\n",
        "\n",
        "    Args:\n",
        "        entity_names: A list of entity names.\n",
        "\n",
        "    Returns:\n",
        "        A list of standardized entity names.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = \"Standardize the following entity names:\\n\"\n",
        "    for entity_name in entity_names:\n",
        "        prompt += f\"{entity_name}\\n\"\n",
        "\n",
        "    response = openai.Text.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=prompt,\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"text\"].split(\"\\n\")"
      ],
      "metadata": {
        "id": "5mWCf90KEW9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample usage\n",
        "automated_sam_data_standardized = automate_standardization(sam_data_cleaned[:100])\n",
        "automated_eproc_data_standardized = automate_standardization(eproc_data_cleaned[:100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "g5QMWqrWEcVL",
        "outputId": "b31aaa5f-10b9-4b43-8187-519d860e4efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-923e4da931a9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mautomated_sam_data_standardized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautomate_standardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msam_data_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mautomated_eproc_data_standardized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautomate_standardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meproc_data_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-0a8a6f017479>\u001b[0m in \u001b[0;36mautomate_standardization\u001b[0;34m(entity_names)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"{entity_name}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     response = openai.Text.create(\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'Text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def batch_process_data(entity_names, batch_size=50):\n",
        "    # Process data in batches\n",
        "    batches = [entity_names[i:i+batch_size] for i in range(0, len(entity_names), batch_size)]\n",
        "    processed_data = []\n",
        "\n",
        "    for batch in batches:\n",
        "        # Process each batch (replace this with your processing logic)\n",
        "        processed_batch = process_batch(batch)\n",
        "        processed_data.extend(processed_batch)\n",
        "\n",
        "    return processed_data\n"
      ],
      "metadata": {
        "id": "z_DSvs4WEhFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example function for processing a batch\n",
        "def process_batch(batch):\n",
        "\n",
        "    processed_batch = [name.upper() for name in batch]  # Example: Convert names to uppercase\n",
        "    return processed_batch\n",
        "\n",
        "\n",
        "processed_sam_data = batch_process_data(sam_data_standardized)\n",
        "\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def parallel_process_data(entity_names):\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        processed_data = list(executor.map(process_single_entity, entity_names))\n",
        "\n",
        "    return processed_data"
      ],
      "metadata": {
        "id": "iMZNX20IKnek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_single_entity(entity_name):\n",
        "\n",
        "    processed_entity = entity_name.lower()  # Example: Convert the name to lowercase\n",
        "    return processed_entity\n",
        "\n",
        "\n",
        "processed_eproc_data = parallel_process_data(eproc_data_standardized)\n"
      ],
      "metadata": {
        "id": "wSdAg-42KsXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Asynchronous Processing\n",
        "import asyncio\n",
        "\n",
        "async def asynchronous_process_data(entity_names):\n",
        "\n",
        "    processed_data = await asyncio.gather(*[process_single_entity_async(name) for name in entity_names])\n",
        "\n",
        "    return processed_data"
      ],
      "metadata": {
        "id": "f4EfczQlKvY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "async def process_single_entity_async(entity_name):\n",
        "\n",
        "    processed_entity = entity_name.capitalize()  # Example: Capitalize the name\n",
        "    return processed_entity\n"
      ],
      "metadata": {
        "id": "EEq-7goZKx8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/process_data', methods=['POST'])\n",
        "def process_data():\n",
        "    data = request.json.get('data')\n",
        "    processed_data = process_batch(data)\n",
        "    return jsonify({'processed_data': processed_data})"
      ],
      "metadata": {
        "id": "JXs23YOkK05y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj-auX-6K5jl",
        "outputId": "748a8afb-3671-4b6a-da11-069a3bff7a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4fBdpgVkLB3D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}